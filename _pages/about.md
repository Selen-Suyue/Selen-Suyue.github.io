---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<html> 
<head>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Permanent+Marker&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Fredericka+the+Great&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Homemade+Apple&display=swap');
        body {
            background-color:	 #FFF0F5;
            font-family: Arial Rounded MT Bold', 'Verdana', sans-serif;
        }
        .main-heading {
            font-family: 'Permanent Marker', cursive;
            text-align: center;
            color: #87CEFA;
        }
    </style>
</head>
<body>
<h1 class="main-heading">Hi there <img src="images/Hi.gif" width="40px"> Welcome to my secret base!</h1>
</body>
</html>
I am a junior at [Xidian University](https://www.xidian.edu.cn/), currently pursuing research in robot learning with a focus on visual perception and object affordance under the guidance of [Prof. Lixin Yang](https://lixiny.github.io/) and [Prof. Cewu Lu](https://www.mvig.org/index.html) at the [MVIG Lab](https://www.mvig.org/index.html), [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/). My ultimate goal is to create robots capable of autonomous exploration and learning through interaction with the environment.  

Previously, during my sophomore year, I contributed to research on adversarial attacks against computer vision systems at the [Key Laboratory of Cooperative Intelligent Systems, Ministry of Education](https://cois.xidian.edu.cn/index.htm), under the supervision of [Prof. Hao Li](https://web.xidian.edu.cn/haoli/) and [Prof. Maoguo Gong](https://web.xidian.edu.cn/mggong/). This experience instilled in me a deep appreciation for the importance of robustness and security in vision-based systems, particularly for applications in agents' autonomous exploration.

News
---------------
- *I'm in charge of the Research Department for our school's [Microsoft Club](https://github.com/MSC-XDU). Feel free to reach out if you'd like to join.*
- *I have set up a [Personal Blog](https://www.cnblogs.com/SelenBlog), welcome everyone to visit!*

Research Experience
--------------
<div style="display: flex; align-items: center;">
    <img src="images/XDU.png" alt="Xi'dian logo" width="60" height="60" style="margin-right: 20px;">
    <div>
        <strong>Xidian University (XDU)</strong><br>
        September 2023 - July 2024<br>
        Research intern at <a href="https://web.xidian.edu.cn/mggong/"><em>OMEGA</em></a> Lab 
    </div>
</div>
<br>

<div style="display: flex; align-items: center;">
    <img src="images/SJTU.png" alt="SJTU logo" width="60" height="60" style="margin-right: 20px;">
    <div>
        <strong>Shanghai Jiao Tong University (SJTU)</strong><br>
        July 2024 -  Now<br>
        Research intern at <a href="https://www.mvig.org/index.html"><em>MVIG</em></a> Lab 
    </div>
</div> 

Publications
--------------

Projects
--------------
<strong>Adversarial Attack<strong>

<div style="display: flex; align-items: center;">
    <img src="images/RAA.png" alt="RIaa" width="240" height="120" style="margin-right: 20px;">
    <div>
        <strong>Adversarial Attacks on Multimodal Image Matching</strong><br>
        We propose Edge-Attack, a physical adversarial attack that probes VI-ReID models' ability to excavate deep-level feature spaces by perturbing modality-invariant shallow-level features. By generating realistic adversarial patches, we test models' robustness in leveraging deep-level implicit features. Edge-Attack exposes the vulnerability of sota VI-ReID models, highlighting the need for more robust feature extraction. <i>This work has been submitted to AAAI2025.</i> &#x1F680;<br>
    </div>
</div>

<br>

<div style="display: flex; align-items: center;">
    <img src="images/iraa.png" alt="Raa" width="240" height="120" style="margin-right: 20px;">
    <div>
        <strong>Infrared adversarial attacks on pedestrian detection</strong><br>
       In the past, real-world infrared adversarial attacks were one-off attacks and difficult to deploy. We used TEC to implement efficient infrared adversarial attacks that can adapt to scenarios in hardware. It can induce pedestrian detection models in infrared scenarios to make misjudgments. <i>This work has been submitted to AAAI2025.</i> &#x1F680;
    </div>
</div>

<br>

<strong>Robot Learning<strong>


Selected Awards
----------------


